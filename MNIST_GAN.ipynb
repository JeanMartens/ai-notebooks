{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61156e58-f844-4cac-aac7-62ba4ed418e7",
   "metadata": {},
   "source": [
    "# Making a GAN to generate MNIST digits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1c807f-6b5c-41d9-b7d8-8f502f9a6000",
   "metadata": {},
   "source": [
    "## Boring imports and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74e8e532-b581-463f-ab63-837f3fb3a571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sklearn.model_selection as ms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "505265c9-fc2b-452d-959f-371022f5016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Dataset(Dataset):\n",
    "    def __init__(self, metadata_df, images):\n",
    "        self.metadata_df = metadata_df\n",
    "        self.images = images / 255\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata_df)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        idx = int(idx)\n",
    "\n",
    "        image = torch.tensor(images[idx])\n",
    "        # label = torch.tensor(self.metadata_df.loc[idx, 'labels'])\n",
    "        label = torch.tensor([1])\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6349e2b-0c66-4e39-b2b6-838129a81716",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('data/MNIST/metadata.csv')\n",
    "train_metadata, test_metadata = ms.train_test_split(metadata, test_size=0.2, train_size=0.8, random_state=19, shuffle=True, stratify=metadata['labels'])\n",
    "\n",
    "images = np.load('data/MNIST/images.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbd9c997-afb5-40b9-bd3e-ad2515c950e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MNIST_Dataset(train_metadata.reset_index(), images[train_metadata.index])\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1a7e95-8842-4335-90c4-257b5947b651",
   "metadata": {},
   "source": [
    "## Fun part: models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "152654eb-0277-4b08-9280-f84f7acc9afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have no idea if this is the way to make the generator/discriminator but I'll do it in a encoder/decoder way since thats the intuition I have about it\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self,num_latent_features):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.first_linear = nn.Sequential(\n",
    "            nn.Linear(num_latent_features,1024),\n",
    "            nn.ReLU() ) \n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        \n",
    "            nn.ConvTranspose2d(64, 1, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "        \n",
    "            nn.Conv2d(1, 1, kernel_size=5, stride=1, padding=0),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_linear(x).view(-1,1024,1,1)\n",
    "        x = self.decoder(x);\n",
    "        return x\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,num_embeddings):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.num_embeddings = num_embeddings\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            # 32x32 to 28x28\n",
    "            nn.Conv2d(1, 64, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # 28x28 to 14x14\n",
    "            nn.Conv2d(64, 128, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "        \n",
    "            # 14x14 to 7x7\n",
    "            nn.Conv2d(128, 256, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "        \n",
    "            # 7x7 to 3x3\n",
    "            nn.Conv2d(256, 512, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "        \n",
    "            # 3x3 to 1x1\n",
    "            nn.Conv2d(512, self.num_embeddings, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.num_embeddings, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x).view(-1,self.num_embeddings)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7c820d7-b40a-4a7d-937d-868437079850",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn' has no attribute 'Adam'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m d \u001b[38;5;241m=\u001b[39m Discriminator(num_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1024\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      6\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCEWithLogitsLoss()\n\u001b[0;32m----> 8\u001b[0m d_optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m(d\u001b[38;5;241m.\u001b[39mparams())\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.nn' has no attribute 'Adam'"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "g = Generator(num_latent_features = 10).to(device)\n",
    "d = Discriminator(num_embeddings = 1024).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "d_optimizer = nn.optim.Adam(d.parameters(), lr=1e-5, weight_decay=0)\n",
    "g_optimizer = nn.optim.Adam(g.parameters(), lr=1e-5, weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c75ab70-6d6b-4f0a-9077-2397f095a0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dups = g(torch.randn(10,10)) # (10,1,28,28)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b150098d-4e37-434a-8492-95aa298865c4",
   "metadata": {},
   "source": [
    "## discriminator functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79c8c4b7-b32a-42c6-a40f-632e7ddf0f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_train(batch,generator, discriminator, device,optimizer, criterion):\n",
    "    discriminator.train()\n",
    "    generator.eval()\n",
    "    \n",
    "    images, labels = batch\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    random_latent_spaces = torch.distributions.Normal(0, 1).sample((len(labels), 10))\n",
    "    with torch.no_grad():\n",
    "        fake_images = generator(random_latent_spaces)\n",
    "\n",
    "    images, labels = torch.cat([images, fake_images],0), torch.cat([labels, torch.zeros((len(labels), ))])\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    outputs = discriminator(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    optimizer.backward(loss)\n",
    "    optimizer.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        metric = ((torch.sigmoid(outputs) > 0.5) == labels) / len(labels)\n",
    "\n",
    "    return loss,metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc78b606-339c-4928-9d07-1c4ed3c33084",
   "metadata": {},
   "source": [
    "## generator functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58dea063-802e-4737-8de5-3271198b10db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_train(batch_size, generator ,discriminator, device,optimizer, criterion):\n",
    "    generator.train()\n",
    "    discriminator.eval()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    random_latent_spaces = torch.distributions.Normal(0, 1).sample((batch_size, 10))\n",
    "    outputs = discriminator(random_latent_spaces)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        crediblity = discriminator(outputs)\n",
    "\n",
    "\n",
    "        \n",
    "    loss = criterion(crediblity, torch.ones((batch_size,)))\n",
    "    optimizer.backward(loss)\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        random_idxs = torch.randint(0,batch_size,(5,))\n",
    "        for i,idx in enumerate(random_idxs):\n",
    "            plt.subplot(1,5,i)\n",
    "            plt.imshow(outputs[idx])\n",
    "        plt.show()\n",
    "            \n",
    "\n",
    "    return loss,metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c70a137-f7f8-4a8d-b86d-4fee2e76907f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 20/219 [00:00<00:02, 97.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 51/219 [00:00<00:01, 132.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 84/219 [00:00<00:00, 148.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 117/219 [00:00<00:00, 154.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 150/219 [00:01<00:00, 156.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 183/219 [00:01<00:00, 158.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 216/219 [00:01<00:00, 158.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219/219 [00:01<00:00, 148.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217\n",
      "218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(tqdm(train_loader, total = len(train_loader))):\n",
    "    d_train(batch,g, d, device ,d_optimizer, criterion)\n",
    "    g_train(32, g, d, device ,d_optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c010cb97-f466-4721-8a13-24b3952bddb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
